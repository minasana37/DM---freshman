fit_group <- lavaan::sem(model, data = scores_scaled, group = "IDCNTRY")
summary(fit_group, fit.measures = TRUE)
# 将IDCNTRY列转换为因子类型
merged_data <- merged_data[!is.na(merged_data$CNTRY), ]
merged_data$CNTRY <- factor(merged_data$CNTRY)
# 再次运行SEM模型
fit_group <- lavaan::sem(model, data = scores_scaled, group = "IDCNTRY")
# 再次运行SEM模型
fit_group <- lavaan::sem(model, data = merged_data, group = "IDCNTRY")
# 再次运行SEM模型
fit_group <- lavaan::sem(model1, data = merged_data, group = "IDCNTRY")
summary(fit_group, fit.measures = TRUE)
# 再次运行SEM模型
fit_group <- lavaan::sem(model1, data = merged_data, group = "IDCNTRY")
# 再次运行SEM模型
fit_group <- lavaan::sem(model1, data = merged_data, group = "CNTRY")
summary(fit_group, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates <- lavaan::parameterEstimates(fit_group)
regression_estimates <- param_estimates[param_estimates$op == "~", ]
# 按照国家分组查看结果
split(regression_estimates, regression_estimates$group)
# 再次运行SEM模型2
fit_group2 <- lavaan::sem(model2, data = merged_data, group = "CNTRY")
summary(fit_group2, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates2 <- lavaan::parameterEstimates(fit_group2)
regression_estimates2 <- param_estimates2[param_estimates$op == "~", ]
# 按照国家分组查看结果
split(regression_estimates1, regression_estimates1$group)
# 按照国家分组查看结果
split(regression_estimates2, regression_estimates2$group)
# 再次运行SEM模型3
fit_group3 <- lavaan::sem(model3, data = merged_data, group = "CNTRY")
summary(fit_group3, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates3 <- lavaan::parameterEstimates(fit_group3)
regression_estimates3 <- param_estimates1[param_estimates$op == "~", ]
# 再次运行SEM模型3
fit_group3 <- lavaan::sem(model3, data = merged_data, group = "CNTRY")
summary(fit_group3, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates3 <- lavaan::parameterEstimates(fit_group3)
regression_estimates3 <- param_estimates3[param_estimates$op == "~", ]
# 按照国家分组查看结果
split(regression_estimates3, regression_estimates3$group)
# 再次运行SEM模型4
fit_group4 <- lavaan::sem(model4, data = merged_data, group = "CNTRY")
summary(fit_group4, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates4 <- lavaan::parameterEstimates(fit_group4)
regression_estimates4 <- param_estimates4[param_estimates$op == "~", ]
# 按照国家分组查看结果
split(regression_estimates4, regression_estimates4$group)
summary(fit1, fit.measures = TRUE, standardized = TRUE)
# 按照国家分组查看结果
split(regression_estimates3, regression_estimates3$group)
summary(fit1, fit.measures = TRUE, standardized = TRUE)
#校长学习领导力 → 组织氛围
model1 <- '
# 组织氛围
T3STUD =~ TT3G49A + TT3G49B + TT3G49C + TT3G49D
T3COLES =~ TT3G33A + TT3G33B + TT3G33C + TT3G33H
# 领导力影响组织氛围
T3STUD ~ T3PLEADS_score
T3COLES ~ T3PLEADS_score
'
summary(fit1, fit.measures = TRUE, standardized = TRUE)
# 按照国家分组查看结果
split(regression_estimates1, regression_estimates1$group)
# 再次运行SEM模型2
fit_group2 <- lavaan::sem(model2, data = merged_data, group = "CNTRY")
# 再次运行SEM模型1
fit_group1 <- lavaan::sem(model1, data = merged_data, group = "CNTRY")
summary(fit_group1, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates1 <- lavaan::parameterEstimates(fit_group1)
regression_estimates1 <- param_estimates1[param_estimates$op == "~", ]
# 按照国家分组查看结果
split(regression_estimates1, regression_estimates1$group)
#校长学习领导力 → 教师情感
model2 <- '
# 教师情感
T3TEAM =~ TT3G32A + TT3G32B + TT3G32C + TT3G32D
T3SELF =~ TT3G34A + TT3G34B + TT3G34C + TT3G34D + TT3G34E + TT3G34F + TT3G34G + TT3G34H + TT3G34I + TT3G34J + TT3G34K + TT3G34L
TT3G49E ~~ TT3G49E  # 这个变量只有一个观测量，不能建因子，直接建回归
# 领导力影响教师情感
T3TEAM ~ T3PLEADS_score
T3SELF ~ T3PLEADS_score
TT3G49E ~ T3PLEADS_score
'
fit2 <- sem(model2, data = merged_data, missing = "fiml")
summary(fit2, fit.measures = TRUE, standardized = TRUE)
# 再次运行SEM模型2
fit_group2 <- lavaan::sem(model2, data = merged_data, group = "CNTRY")
summary(fit_group2, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates2 <- lavaan::parameterEstimates(fit_group2)
regression_estimates2 <- param_estimates2[param_estimates$op == "~", ]
# 按照国家分组查看结果
split(regression_estimates2, regression_estimates2$group)
#校长学习领导力 → 课堂教学
model3 <- '
# 课堂教学
T3TPRA =~ TT3G42A + TT3G42B + TT3G42C + TT3G42D + TT3G42E + TT3G42F + TT3G42G + TT3G42H + TT3G42I + TT3G42J + TT3G42K + TT3G42L
T3DISC =~ TT3G41A + TT3G41B + TT3G41C + TT3G41D
# 领导力影响课堂教学
T3TPRA ~ T3PLEADS_score
T3DISC ~ T3PLEADS_score
'
fit3 <- sem(model3, data = merged_data, missing = "fiml")
summary(fit3, fit.measures = TRUE, standardized = TRUE)
# 再次运行SEM模型3
fit_group3 <- lavaan::sem(model3, data = merged_data, group = "CNTRY")
summary(fit_group3, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates3 <- lavaan::parameterEstimates(fit_group3)
regression_estimates3 <- param_estimates3[param_estimates$op == "~", ]
# 按照国家分组查看结果
split(regression_estimates3, regression_estimates3$group)
summary(fit4, fit.measures = TRUE, standardized = TRUE)
#如果你认为校长学习领导力 T3PLEADS 的影响受其他因素调节（如 T3COLES 或 T3TEAM），可以添加交互项。例如，教师专业合作调节领导力对师生关系的影响：
#交互项需要提前加入数据集之中
# 计算交互项，并加入数据集
summary(merged_data$T3PLEADS_score)
fit4 <- sem(model4, data = merged_data, missing = "fiml")
summary(fit4, fit.measures = TRUE, standardized = TRUE)
summary(fit1, fit.measures = TRUE, standardized = TRUE)
library(car)
install.packages("car")
library(car)
model <- lm(T3COLES ~ TT3G33A + TT3G33B + TT3G33C + TT3G33H + T3PLEADS_score, data = data_frame)
model <- lm(T3COLES ~ TT3G33A + TT3G33B + TT3G33C + TT3G33H + T3PLEADS_score, data = merged_data)
model <- lm(T3COLES_score ~ TT3G33A + TT3G33B + TT3G33C + TT3G33H + T3PLEADS_score, data = merged_data)
vif(model)
vif_values <- vif(model)
tolerance_values <- 1 / vif_values
tolerance_values
model <- lm(T3PLEADS_score ~ TT3G33A + TT3G33B + TT3G33C + TT3G33H , data = merged_data)
vif(model)
vif_values <- vif(model)
tolerance_values <- 1 / vif_values
tolerance_values
model <- lm(T3PLEADS_score ~ TT3G33A + TT3G33B + TT3G33C + TT3G33H+TT3G33A + TT3G33B + TT3G33C + TT3G33H , data = merged_data)
vif(model)
vif_values <- vif(model)
model <- lm(T3PLEADS_score ~ TT3G49A + TT3G49B + TT3G49C + TT3G49D+TT3G33A + TT3G33B + TT3G33C + TT3G33H , data = merged_data)
vif(model)
vif_values <- vif(model)
tolerance_values <- 1 / vif_values
tolerance_values
# 再次运行SEM模型1
fit_group1 <- lavaan::sem(model1, data = merged_data, group = "CNTRY")
summary(fit_group1, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates1 <- lavaan::parameterEstimates(fit_group1)
regression_estimates1 <- param_estimates1[param_estimates$op == "~", ]
# 按照国家分组查看结果
split(regression_estimates1, regression_estimates1$group)
merged_data$CNTRY
#########校长学习领导力 → 教师情感
model2 <- '
# 教师情感
T3TEAM =~ TT3G32A + TT3G32B + TT3G32C + TT3G32D
T3SELF =~ TT3G34A + TT3G34B + TT3G34C + TT3G34D + TT3G34E + TT3G34F + TT3G34G + TT3G34H + TT3G34I + TT3G34J + TT3G34K + TT3G34L
TT3G49E ~~ TT3G49E  # 这个变量只有一个观测量，不能建因子，直接建回归
# 领导力影响教师情感
T3TEAM ~ T3PLEADS_score
T3SELF ~ T3PLEADS_score
TT3G49E ~ T3PLEADS_score
'
fit2 <- sem(model2, data = merged_data, missing = "fiml")
summary(fit2, fit.measures = TRUE, standardized = TRUE)
#校长学习领导力 → 课堂教学
model3 <- '
# 课堂教学
T3TPRA =~ TT3G42A + TT3G42B + TT3G42C + TT3G42D + TT3G42E + TT3G42F + TT3G42G + TT3G42H + TT3G42I + TT3G42J + TT3G42K + TT3G42L
T3DISC =~ TT3G41A + TT3G41B + TT3G41C + TT3G41D
# 领导力影响课堂教学
T3TPRA ~ T3PLEADS_score
T3DISC ~ T3PLEADS_score
'
fit3 <- sem(model3, data = merged_data, missing = "fiml")
summary(fit3, fit.measures = TRUE, standardized = TRUE)
model4 <- '
# 组织氛围（潜变量）
T3STUD =~ TT3G49A + TT3G49B + TT3G49C + TT3G49D
T3COLES =~ TT3G33A + TT3G33B + TT3G33C + TT3G33H
# 领导力影响师生关系，教师专业合作为调节变量
T3STUD ~ T3PLEADS_score + T3COLES + interaction_term
'
fit4 <- sem(model4, data = merged_data, missing = "fiml")
summary(fit4, fit.measures = TRUE, standardized = TRUE)
model4 <- '
# 组织氛围（潜变量）
T3STUD =~ TT3G49A + TT3G49B + TT3G49C + TT3G49D
T3COLES =~ TT3G33A + TT3G33B + TT3G33C + TT3G33H
# 领导力影响师生关系，教师专业合作为调节变量
T3PLEADS_score ~T3STUD  + T3COLES + interaction_term
'
fit4 <- sem(model4, data = merged_data, missing = "fiml")
summary(fit4, fit.measures = TRUE, standardized = TRUE)
merged_data$interaction_term <- merged_data$T3PLEADS_score * merged_data$T3COLES_score
model4 <- '
# 组织氛围（潜变量）
T3STUD =~ TT3G49A + TT3G49B + TT3G49C + TT3G49D
T3COLES =~ TT3G33A + TT3G33B + TT3G33C + TT3G33H
# 领导力影响师生关系，教师专业合作为调节变量
T3PLEADS_score ~T3STUD  + T3COLES + interaction_term
'
fit4 <- sem(model4, data = merged_data, missing = "fiml")
summary(fit4, fit.measures = TRUE, standardized = TRUE)
# 再次运行SEM模型4
fit_group4 <- lavaan::sem(model4, data = merged_data, group = "CNTRY")
summary(fit_group4, fit.measures = TRUE)
# 提取回归系数和参数估计
param_estimates4 <- lavaan::parameterEstimates(fit_group4)
regression_estimates4 <- param_estimates4[param_estimates$op == "~", ]
# 按照国家分组查看结果
split(regression_estimates4, regression_estimates4$group)
cancer<-read.table(url("http://www.stats.gla.ac.uk/~tereza/rp/cancer.txt"),
header=TRUE)
gc()
cancer<-read.table(url("http://www.stats.gla.ac.uk/~tereza/rp/cancer.txt"),
header=TRUE)
head(cancer)
ggpairs(cancer[,c(-1,-3)],
upper=list(continuous=wrap("points",alpha=0.4, color="#d73027")),
lower="blank",axisLabels="none")
library(ggplot2)
ggpairs(cancer[,c(-1,-3)],
upper=list(continuous=wrap("points",alpha=0.4, color="#d73027")),
lower="blank",axisLabels="none")
library(GGally)
install.packages("GGally")
ggpairs(cancer[,c(-1,-3)],
upper=list(continuous=wrap("points",alpha=0.4, color="#d73027")),
lower="blank",axisLabels="none")
library(GGally)
ggpairs(cancer[,c(-1,-3)],
upper=list(continuous=wrap("points",alpha=0.4, color="#d73027")),
lower="blank",axisLabels="none")
cancer<-read.table(url("http://www.stats.gla.ac.uk/~tereza/rp/cancer.txt"),
header=TRUE)
head(cancer)
library(GGally)
ggpairs(cancer[,c(-1,-3)],
upper=list(continuous=wrap("points",alpha=0.4, color="#d73027")),
lower="blank",axisLabels="none")
epid1<-glm(Y_all~pm10+smoke+ethnic+log.price+easting+
northing+offset(log(E_all)), family=poisson, data=cancer)
summary(epid1)
library(faraway)
install.packages("faraway")
library(faraway)
head(gala)
ggpairs(gala, upper=list(continuous=wrap("points", alpha=0.4, color="#d73027")),
lower="blank", axisLabels="none")
gal1 <- glm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent,
family = poisson, data = gala)
summary(gal1)
# 计算 Pearson 统计量
pearson_chi_sq <- sum(residuals(gal1, type = "pearson")^2)
pearson_chi_sq
resp<-resid(gal1,type= "pearson")
resp
resd<-resid(gal1,type= "deviance")
p1<-ggplot(gal1,aes(sample=resp))+geom_point(stat="qq",color= "#7fc97f")+
ylab("Pearsonresiduals")
p2<-ggplot(gal1,aes(sample =resd))+geom_point(stat="qq",color= "#7fc97f")+
ylab("Devianceresiduals")
p3<-ggplot(gal1,aes(x=predict(gal1,type="link"), y=resd))+
geom_point(col="#7fc97f")+
ylab("Devianceresiduals")+xlab("Linearpredictor")
grid.arrange(p1,p2,p3,nrow=1)
library(gridExtra)
grid.arrange(p1,p2,p3,nrow=1)
p4<-ggplot(gal1,aes(x=predict(gal1,type="link"), y=resp))+
geom_point(col="#7fc97f")+
ylab("Devianceresiduals")+xlab("Linearpredictor")
library(gridExtra)
grid.arrange(p1,p2,p3,p4,nrow=2)
ggplot(gal1,aes(x=log(fitted(gal1)), y=log((gala$Species-fitted(gal1))ˆ2)))+
ggplot(gal1,aes(x=log(fitted(gal1)), y=log((gala$Species-fitted(gal1))ˆ2)))+
ggplot(gal1,aes(x=log(fitted(gal1)), y=log((gala$Species-fitted(gal1))ˆ2)))+
ggplot(gal1,aes(x=log(fitted(gal1)), y=log((gala$Species-fitted(gal1))^2)))+
geom_point(col="#f46d43")+
geom_abline(slope=1,intercept=0,col="#a6d96a",size=1)+
ylab(expression((y-hat(mu))^2))+
xlab(expression(hat(mu)))
#######################
X2 <- sum(resid(gal1, type = "pearson")ˆ2)#pearson_chi_sq
#######################
X2 <- sum(resid(gal1, type = "pearson")^2)#pearson_chi_sq
dp <- X2 / gal1$df.res
dp
summary(gal1, dispersion = dp)
summary(gal1)
drop1(gal1, test = "F")
# Residual plots vs. predicted
pred <- predict(gal1, type = "response")
stand.resid <- rstandard(model = gal1, type = "pearson") # Standardised Pearson residuals
par(mfrow=c(1,2))
plot(x = pred, y = stand.resid, xlab = "Predicted count", ylab = "Standardised Pearson residuals",
main = "Regular likelihood", ylim = c(-5,5))
abline(h = c(-3,-2, 0, 2, 3), lty = "dotted", col = "red")
gal2 <- glm(Species ~ Area + Elevation + Nearest + Scruz + Adjacent,
family = quasipoisson(link = "log"), data = gala) # Quasi-Poisson model
pred <- predict(gal2, type = "response")
stand.resid <- rstandard(model = gal2, type = "pearson") # Standardised Pearson residuals
plot(x = pred, y = stand.resid, xlab = "Predicted count", ylab = "Standardised Pearson residuals",
main = "Quasi-likelihood", ylim = c(-5,5))
abline(h = c(-3,-2, 0, 2, 3), lty = "dotted", col = "red")
####################Negativebinomialmodel
library(MASS)
gal3<-glm.nb(Species~Area+Elevation+Nearest+Scruz+Adjacent,
data= gala)
summary(gal3)
c(gal1$deviance, gal1$aic)
c(gal3$deviance, gal3$aic)
# Plot of squared residuals v predicted values
res.sq <- residuals(gal1, type = "response")ˆ2
# Plot of squared residuals v predicted values
res.sq <- residuals(gal1, type = "response")^2
set1 <- data.frame(res.sq, mu.hat = gal1$fitted.values)
fit.lin <- lm(formula = res.sq ~ mu.hat, data = set1)
fit.quad <- lm(formula = res.sq ~ mu.hat + I(mu.hat^2), data = set1)
summary(fit.quad)
plot(set1$mu.hat,y= set1$res.sq, xlab="Predictedcount",
ylab="SquaredResidual")
curve(expr= predict(fit.lin,newdata= data.frame(mu.hat=x),type= "response"),
col="blue", add=TRUE, lty="solid")
curve(expr= predict(fit.quad,newdata= data.frame(mu.hat=x), type="response"),
col="red", add=TRUE,lty="dashed")
legend("topleft",legend= c("Linear","Quadratic"),col= c("blue","red"),
lty=c("solid","dashed"), bty="n")
par(mfrow=c(1,1))
plot(set1$mu.hat,y= set1$res.sq, xlab="Predictedcount",
ylab="SquaredResidual")
curve(expr= predict(fit.lin,newdata= data.frame(mu.hat=x),type= "response"),
col="blue", add=TRUE, lty="solid")
curve(expr= predict(fit.quad,newdata= data.frame(mu.hat=x), type="response"),
col="red", add=TRUE,lty="dashed")
legend("topleft",legend= c("Linear","Quadratic"),col= c("blue","red"),
lty=c("solid","dashed"), bty="n")
###############
olympics0<-read.csv(url("http://www.stats.gla.ac.uk/~tereza/rp/OlympicMedals2012.csv"))
olympics<-data.frame(country= olympics0$Country, medals=olympics0$Medals,
population=olympics0$Population,
gold =olympics0$Gold.Medal,
GDP=olympics0$GDP..US.Billion)
olympics$GDPpercapita<-olympics$GDP*10ˆ6/olympics$population
head(olympics)
olympics$GDPpercapita<-olympics$GDP*10^6/olympics$population
head(olympics)
p1<-ggplot(olympics,aes(x=log(population), y=log(medals)))+
geom_point(col="#f46d43")
p2<-ggplot(olympics,aes(x=log(GDPpercapita), y=log(medals)))+
geom_point(col="#f46d43")
grid.arrange(p1,p2,nrow=1)
ol1<-glm(medals~log(population)+log(GDPpercapita),
family=poisson,data= olympics)
summary(ol1)
setwd("D:/work/Github/Data-Mining")
library(dplyr)
data<-read.csv("group_37.csv")
total_na <- sum(is.na(data))
total_na
sum(is.na(data))
is.na(data)
sum(is.na(data))
View(data)
target <- data[, 1]
features <- data[, -1]
feature_variances <- apply(features, 2, var, na.rm = TRUE)
feature_variances <- apply(features, 2, var)
boxplot(feature_variances, col = "lightblue", border = "blue",horizontal = FALSE)
boxplot(feature_variances, col = "lightblue", border = "blue"）
boxplot(feature_variances, col = "lightblue", border = "blue")
variance_threshold <- 0.01
selected_features_var <- features[, feature_variances > variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(selected_features_var), "\n")
#person
cor_values <- apply(selected_features_var, 2, function(x) cor(x, target, method = "spearman", use = "complete.obs"))
cor_threshold <- 0.2
selected_features_cor <- selected_features_var[, abs(cor_values) > cor_threshold]
cat("🔹 经过相关性筛选，最终剩余特征数:", ncol(selected_features_cor), "\n")
variance_threshold <- 0.001
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(removed_features_var), "\n")
variance_threshold <- 0.01
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(removed_features_var), "\n")
variance_threshold <- 0.02
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(removed_features_var), "\n")
variance_threshold <- 0.1
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(removed_features_var), "\n")
variance_threshold <- 0.2
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(removed_features_var), "\n")
variance_threshold <- 0.4
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(removed_features_var), "\n")
#方差
feature_variances <- apply(features, 2, sd)
boxplot(feature_variances, col = "lightblue", border = "blue")
variance_threshold <- 0.01
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(removed_features_var), "\n")
variance_threshold <- 0.1
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(removed_features_var), "\n")
variance_threshold <- 200
selected_features_var <- features[, feature_variances > variance_threshold]
removed_features_var <- features[, feature_variances < variance_threshold]
cat("🔹 经过方差筛选，剩余特征数:", ncol(selected_features_var), "\n")
cat("🔹 经过方差筛选，移除特征数:", ncol(removed_features_var), "\n")
filtered_data <- cbind(target, selected_features_var)
target <- filtered_data[, 1]  # 目标变量
features <- filtered_data[, -1]  # 特征数据
# ===== 2. 划分训练集和测试集 =====
set.seed(123)  # 设置随机种子，确保结果可重现
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)  # 70%训练集，30%测试集
trainData <- filtered_data[trainIndex, ]  # 训练数据
library(randomForest)
library(caret)
install.packages("randomForest")
library(randomForest)
library(caret)
target <- filtered_data[, 1]  # 目标变量
features <- filtered_data[, -1]  # 特征数据
# ===== 2. 划分训练集和测试集 =====
set.seed(123)  # 设置随机种子，确保结果可重现
trainIndex <- createDataPartition(target, p = 0.7, list = FALSE)  # 70%训练集，30%测试集
trainData <- filtered_data[trainIndex, ]  # 训练数据
testData <- filtered_data[-trainIndex, ]  # 测试数据
train_target <- target[trainIndex]  # 训练集目标变量
test_target <- target[-trainIndex]  # 测试集目标变量
train_features <- features[trainIndex, ]  # 训练集特征
test_features <- features[-trainIndex, ]  # 测试集特征
# ===== 3. 使用逻辑回归进行训练 =====
# 构建逻辑回归模型
log_model <- glm(train_target ~ ., data = trainData, family = binomial)
# ===== 3. 使用逻辑回归进行训练 =====
# 构建逻辑回归模型
train_target <- ifelse(train_target == -1, 0, train_target)
test_target <- ifelse(test_target == -1, 0, test_target)
log_model <- glm(train_target ~ ., data = trainData, family = binomial)
# ===== 4. 对测试集进行预测 =====
# 使用训练好的模型对测试集进行预测
log_predictions <- predict(log_model, testData, type = "response")
library(dplyr)
# ===== 4. 对测试集进行预测 =====
# 使用训练好的模型对测试集进行预测
log_predictions <- predict(log_model, testData, type = "response")
log_predictions <- ifelse(log_predictions > 0.5, 1, -1)  # 将概率转化为类别（1 或 -1）
# ===== 5. 模型评估 =====
# 混淆矩阵
confusionMatrix(as.factor(log_predictions), as.factor(test_target))
# ===== 6. 使用随机森林进行训练（可选） =====
rf_model <- randomForest(train_target ~ ., data = trainData)
# 对测试集进行预测
rf_predictions <- predict(rf_model, testData)
# 随机森林的混淆矩阵
confusionMatrix(as.factor(rf_predictions), as.factor(test_target))
log_model <- glm(train_target ~ ., data = trainData, family = binomial)
log_model$deviance
log_model$null.deviance
# ===== 4. 对测试集进行预测 =====
# 使用训练好的模型对测试集进行预测
log_predictions <- predict(log_model, testData, type = "response")
pca <- prcomp(train_features, center = TRUE, scale. = TRUE)
summary(pca)
train_pca_features <- pca$x[, 1:10]
test_pca_features <- predict(pca, newdata = test_features)[, 1:10]
log_model <- glm(train_target ~ ., data = data.frame(train_pca_features), family = binomial)
# ===== 6. 对测试集进行预测 =====
log_predictions <- predict(log_model, data.frame(test_pca_features), type = "response")
log_predictions <- ifelse(log_predictions > 0.5, 1, 0)  # 将概率转化为类别（0 或 1）
# ===== 7. 模型评估 =====
confusionMatrix(as.factor(log_predictions), as.factor(test_target))
# ===== 8. 使用随机森林进行训练（可选） =====
rf_model <- randomForest(train_target ~ ., data = data.frame(train_pca_features))
# 对测试集进行预测
rf_predictions <- predict(rf_model, data.frame(test_pca_features))
# 随机森林的混淆矩阵
confusionMatrix(as.factor(rf_predictions), as.factor(test_target))
# ===== 7. 模型评估 =====
confusionMatrix(as.factor(log_predictions), as.factor(test_target))
